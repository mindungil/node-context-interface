require('dotenv').config();
const express = require('express');
const path = require('path'); 
const OpenAI = require('openai');
const cors = require('cors'); 

const app = express();
app.use(cors());
app.use(express.json());

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

app.use(express.static(path.join(__dirname, 'public')));

// ğŸŸ¢ ì¬ì‹œë„ í•¨ìˆ˜ - ì‘ë‹µ ë¹„ì–´ìˆì„ ë•Œë„ ì¬ì‹œë„
async function retryRequest(callback, maxRetries = 5) {
  let attempts = 0;
  while (attempts < maxRetries) {
    try {
      const response = await callback();
      const gptResult = response?.choices?.[0]?.message?.content?.trim();
      
      // ì‘ë‹µ ë¹„ì–´ ìˆëŠ” ê²½ìš° ë‹¤ì‹œ ìš”ì²­
      if (!gptResult) {
        throw new Error("GPT ì‘ë‹µì´ ë¹„ì–´ ìˆìŒ - ì¬ì‹œë„");
      }

      return response;
    } catch (error) {
      attempts++;
      console.error(`âŒ ì¬ì‹œë„ ì¤‘... (${attempts}/${maxRetries}) - ì˜¤ë¥˜: ${error.message}`);
      if (attempts >= maxRetries) throw error;
    }
  }
}

app.post('/api/chat', async (req, res) => {  
  const userPrompt = req.body.message;  
  const previousMessages = req.body.history || [];  

  try {
    const response = await retryRequest(() => openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [
        { 
          role: "system", 
          content: "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ í•´ì¤˜"
        },
        ...previousMessages,
        { role: 'user', content: userPrompt },
      ],
      max_tokens: 800,
    }));

    const gptResponse = response.choices[0].message.content;
    
    // ğŸ”¥ ì‘ë‹µì´ ë¹„ì–´ ìˆëŠ” ê²½ìš° ê°•ì œ ì¬ì‹œë„
    if (!gptResponse) {
      console.error("â—ï¸ GPT ì‘ë‹µì´ ë¹„ì–´ ìˆìŒ! ì¬ì‹œë„...");
      throw new Error("Empty response from GPT");
    }

    res.json({ message: gptResponse});
     
  } catch (error) {
    console.error('âŒ Error generating response:', error);
    res.status(500).send('Internal Server Error');
  }
});

app.post('/api/update-graph', async (req, res) => {  
  const { nodes, userMessage, gptMessage } = req.body;  
  const safeNodes = nodes || {};
  const existingKeywords = Object.values(safeNodes).map(node => node.keyword);

  console.log('ğŸ“Œ ì—…ë°ì´íŠ¸ ìš”ì²­ ë°›ìŒ');
  console.log('ğŸ“‹ í˜„ì¬ ë…¸ë“œ ëª©ë¡:', existingKeywords);
  console.log('ğŸ—ºï¸ ì „ë‹¬ëœ ë…¸ë“œ ë°ì´í„°:', JSON.stringify(safeNodes, null, 2));

  try {
    const response = await retryRequest(() => openai.chat.completions.create({
      model: 'gpt-4o',
      messages: [
        {
          role: 'system',
          content: `
          ë‹¤ìŒ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì˜ ëŒ€í™” í‚¤ì›Œë“œë„ ì¶”ì¶œí•˜ê³ ,
          ê·¸ë˜í”„ ì—…ë°ì´íŠ¸ ì •ë³´ë¥¼ ìƒì„±í•˜ì„¸ìš”.

          1. ëŒ€í™” ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ëœ í‚¤ì›Œë“œ 1ê°œë§Œ JSON í˜•íƒœë¡œ ì¶”ì¶œí•˜ì„¸ìš”.
          2. ê·¸ë˜í”„ ë‚´ ì–´ë””ì— ì—°ê²°ë˜ì–´ì•¼ í• ì§€ íŒë‹¨í•˜ê³ , ê°€ì¥ ì—°ê´€ëœ ë¶€ëª¨ ë…¸ë“œë¥¼ ì°¾ì•„ ê´€ê³„ë„ ì„¤ì •í•˜ì„¸ìš”.
          3. ê´€ê³„ëŠ” í•œ ë‹¨ì–´ ë˜ëŠ” ì§§ì€ êµ¬ë¡œ í‘œí˜„í•˜ì„¸ìš”.

          ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
          \`\`\`json
          {
            "keyword": "ì¶”ì¶œëœ í‚¤ì›Œë“œ",
            "parentNodeId": "ë¶€ëª¨ ë…¸ë“œ ID",
            "relation": "ë¶€ëª¨ì™€ì˜ ê´€ê³„"
          }
          \`\`\`
        `
        },
        { role: 'user', content: `í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœ: ${JSON.stringify(safeNodes)}` },
        { role: 'user', content: `í˜„ì¬ ì¡´ì¬í•˜ëŠ” ë…¸ë“œ ëª©ë¡: ${JSON.stringify(existingKeywords)}` },
        { role: 'user', content: `ìµœê·¼ ëŒ€í™” ë‚´ìš©: ${JSON.stringify({ userMessage, gptMessage })}` }
      ],
      max_tokens: 800,
      response_format: { type: "json_object" } 
    }));

    console.log("\nğŸ“ [GPT ì‘ë‹µ ì›ë³¸ - /api/update-graph]:", response.choices[0].message.content);
     
    let gptResult = response.choices[0]?.message?.content?.trim();
    
    if (!gptResult) {
      console.error("âŒ GPT ì‘ë‹µì´ ë¹„ì–´ ìˆìŒ! ì¬ì‹œë„ ì¤‘...");
      throw new Error("Empty GPT response");
    }

    let parsedResult;
    try {
      parsedResult = JSON.parse(gptResult);
    } catch (parseError) {
      console.error("âŒ JSON íŒŒì‹± ì˜¤ë¥˜:", parseError);
      throw new Error("GPT ì‘ë‹µì„ JSONìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ");
    }

    let keyword = parsedResult.keyword?.trim() || "???";
    let parentNodeId = parsedResult.parentNodeId?.trim() || "root";
    let relation = parsedResult.relation?.trim() || "ê´€ë ¨";

    if (!Object.keys(safeNodes).includes(parentNodeId)) {
      parentNodeId = Object.keys(safeNodes).find(key => keyword.includes(safeNodes[key].keyword)) || "root";
    }

    console.log(`âœ… í‚¤ì›Œë“œ: ${keyword}, ì„ íƒëœ ë¶€ëª¨ ë…¸ë“œ: ${parentNodeId}, ê´€ê³„: ${relation}`);
    
    res.json({ keyword, parentNodeId, relation });

  } catch (error) {
    console.error("âŒ Error in Graph Update:", error);
    res.status(500).json({ error: "ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ ë°œìƒ" });
  }
});

app.listen(8080, function () {
  console.log('ğŸš€ Server is listening on port 8080');
});
