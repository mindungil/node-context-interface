require('dotenv').config();
const express = require('express');
const path = require('path'); 
const OpenAI = require('openai');
const cors = require('cors'); 

const app = express();
app.use(cors());
app.use(express.json());

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

app.use(express.static(path.join(__dirname, 'public')));

app.post('/api/chat', async (req, res) => {  
  const userPrompt = req.body.message;  
  const previousMessages = req.body.history || [];  

  // console.log('User Message:', userPrompt);
  // console.log('Previous Messages:', previousMessages);

  try {
    const response = await openai.chat.completions.create({
      model: 'gpt-4o',
      messages: [
        ...previousMessages,  
        { role: 'user', content: userPrompt },
        { 
          role: "system", 
          content: "ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ GPTì˜ ë‹µë³€ì„ ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ëœ í‚¤ì›Œë“œë¥¼ ë‹¨ 1ê°œë§Œ ì¶”ì¶œí•´ì„œ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ ì£¼ì„¸ìš”. JSON í˜•ì‹ ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n\n```json\n{\n  \"response\": \"GPTì˜ ë‹µë³€ ë‚´ìš©\",\n  \"keyword\": \"í‚¤ì›Œë“œ\"\n}\n```"
        }
      ],
      max_tokens: 800,
      response_format: { type: "json_object" } 
    });

    const gptResult = response.choices[0].message.content;
    const parsedResult = JSON.parse(gptResult); 
    const gptResponse = parsedResult.response;
    const keyword = parsedResult.keyword; 
    console.log('GPT Result:', gptResult);
    console.log('keyword:', keyword);

    res.json({ message: gptResponse, keyword});
     
  } catch (error) {
    console.error('Error generating response:', error);
    res.status(500).send('Internal Server Error');
  }
});

app.post('/api/update-graph', async (req, res) => {  
  const { nodes, history, keyword, userMessage, gptMessage } = req.body;  

  const safeNodes = nodes || {};
  const existingKeywords = Object.values(safeNodes).map(node => node.keyword);

  console.log('ğŸ“Œ ê·¸ë˜í”„ ì—…ë°ì´íŠ¸ ìš”ì²­ ë°›ìŒ');
  console.log('í˜„ì¬ ë…¸ë“œ ëª©ë¡:', existingKeywords);

  try {
    const response = await openai.chat.completions.create({
      model: 'gpt-4o',
      messages: [
        { role: 'system', content: `
          1. ì‚¬ìš©ìì˜ ëŒ€í™” ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ìƒˆë¡œìš´ í‚¤ì›Œë“œê°€ ì–´ë””ì— ì—°ê²°ë˜ì–´ì•¼ í•˜ëŠ”ì§€ íŒë‹¨í•´ì¤˜.
          2. ê¸°ì¡´ ë…¸ë“œ ì¤‘ ê°€ì¥ ì—°ê´€ì„±ì´ ë†’ì€ ë…¸ë“œë¥¼ ë¶€ëª¨ ë…¸ë“œë¡œ ì„ íƒí•´ì•¼ í•´.
          3. ë¶€ëª¨ ë…¸ë“œì˜ IDë§Œ ë‹¨ìˆœí•œ í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•˜ê³ , ë‹¤ë¥¸ ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ë§ˆ.
        `},
        { role: 'user', content: `í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœ: ${JSON.stringify(safeNodes)}` },
        { role: 'user', content: `í˜„ì¬ ì¡´ì¬í•˜ëŠ” ë…¸ë“œ ëª©ë¡: ${JSON.stringify(existingKeywords)}` },
        { role: 'user', content: `ìµœê·¼ ëŒ€í™” í‚¤ì›Œë“œ: ${JSON.stringify({ keyword, userMessage, gptMessage })}` },
        { role: 'user', content: "ìƒˆë¡œìš´ ë…¸ë“œë¥¼ ì—°ê²°í•  ë¶€ëª¨ ë…¸ë“œì˜ IDë§Œ ë°˜í™˜í•´." }
      ],
      max_tokens: 50
    });

    let parentNodeId = response.choices[0].message.content.trim();

    // âœ… parentNodeê°€ ê¸°ì¡´ ë…¸ë“œ ëª©ë¡ì— ì—†ìœ¼ë©´ ìë™ ë³´ì •
    if (!Object.keys(safeNodes).includes(parentNodeId)) {
      parentNodeId = Object.keys(safeNodes).find(key => keyword.includes(safeNodes[key].keyword)) || "root";
    }

    console.log(`âœ… ì„ íƒëœ ë¶€ëª¨ ë…¸ë“œ: ${parentNodeId}`);
    
    res.send(parentNodeId);
    
  } catch (error) {
    console.error('Error in Graph Update:', error);
    res.status(500).send('Internal Server Error');
  }
});

app.listen(8080, function () {
  console.log('Server is listening on port 8080');
});
